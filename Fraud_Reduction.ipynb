{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOCtuBKzvsgkbsWtaG2wRUz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aasish357/Fraud-Detection-System-Using/blob/main/Fraud_Reduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6EY3vNIqZdML"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "import pickle\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "import uvicorn\n",
        "from typing import List\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Generate Synthetic Dataset (mimics Kaggle Credit Card Fraud)\n",
        "def generate_synthetic_data(n_samples: int = 10000, fraud_ratio: float = 0.0017) -> pd.DataFrame:\n",
        "    np.random.seed(42)\n",
        "    # 30 features: V1-V28 (PCA components), Amount, Time\n",
        "    data = {\n",
        "        **{f'V{i}': np.random.normal(0, 1, n_samples) for i in range(1, 29)},\n",
        "        'Amount': np.random.exponential(100, n_samples),\n",
        "        'Time': np.random.uniform(0, 172800, n_samples)  # 2 days in seconds\n",
        "    }\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # Generate fraud labels (0 = legit, 1 = fraud)\n",
        "    df['Class'] = 0\n",
        "    fraud_indices = np.random.choice(n_samples, size=int(n_samples * fraud_ratio), replace=False)\n",
        "    df.loc[fraud_indices, 'Class'] = 1\n",
        "\n",
        "    # Add fraud patterns: higher Amount, slight feature shifts\n",
        "    df.loc[fraud_indices, 'Amount'] *= np.random.uniform(2, 5)\n",
        "    for i in range(1, 29):\n",
        "        df.loc[fraud_indices, f'V{i}'] += np.random.normal(1, 0.5, len(fraud_indices))\n",
        "    return df"
      ],
      "metadata": {
        "id": "6cdyL7e1dICT"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 2: Preprocess Data\n",
        "def preprocess_data(df: pd.DataFrame, test_size: float = 0.2):\n",
        "    X = df.drop('Class', axis=1)\n",
        "    y = df['Class']\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, stratify=y, random_state=42)\n",
        "\n",
        "    # Scale features\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # Handle imbalance with SMOTE\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_train_smote, y_train_smote = smote.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "    return X_train_smote, X_test_scaled, y_train_smote, y_test, scaler\n"
      ],
      "metadata": {
        "id": "qNeNwZSrddHc"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Train Models\n",
        "class FraudModels:\n",
        "    def __init__(self):\n",
        "        self.lr_model = LogisticRegression(random_state=42)\n",
        "        self.rf_model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
        "        self.autoencoder = None\n",
        "\n",
        "    def train_logistic_regression(self, X_train, y_train):\n",
        "        self.lr_model.fit(X_train, y_train)\n",
        "        pickle.dump(self.lr_model, open('lr_model.pkl', 'wb'))\n",
        "\n",
        "    def train_random_forest(self, X_train, y_train):\n",
        "        self.rf_model.fit(X_train, y_train)\n",
        "        pickle.dump(self.rf_model, open('rf_model.pkl', 'wb'))\n",
        "\n",
        "    def train_autoencoder(self, X_train, y_train, epochs=50, batch_size=256):\n",
        "        # Use only non-fraud data for training\n",
        "        X_normal = X_train[y_train == 0]\n",
        "\n",
        "        # Autoencoder architecture\n",
        "        input_dim = X_train.shape[1]\n",
        "        input_layer = Input(shape=(input_dim,))\n",
        "        encoder = Dense(14, activation='relu')(input_layer)\n",
        "        encoder = Dense(7, activation='relu')(encoder)\n",
        "        decoder = Dense(14, activation='relu')(encoder)\n",
        "        decoder = Dense(input_dim, activation='linear')(decoder)\n",
        "\n",
        "        self.autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
        "        self.autoencoder.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "        self.autoencoder.fit(\n",
        "            X_normal, X_normal,\n",
        "            epochs=epochs, batch_size=batch_size,\n",
        "            shuffle=True, verbose=0\n",
        "        )\n",
        "        self.autoencoder.save('autoencoder.h5')\n",
        "\n",
        "    def predict_lr(self, X):\n",
        "        return self.lr_model.predict(X)\n",
        "\n",
        "    def predict_rf(self, X):\n",
        "        return self.rf_model.predict(X)\n",
        "\n",
        "    def predict_autoencoder(self, X, threshold=2.0):\n",
        "        reconstructions = self.autoencoder.predict(X, verbose=0)\n",
        "        mse = np.mean(np.power(X - reconstructions, 2), axis=1)\n",
        "        return (mse > threshold).astype(int)"
      ],
      "metadata": {
        "id": "TlZtzNe-eunH"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rXFdgkCiez9J"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 4: Evaluate Models\n",
        "def evaluate_model(y_true, y_pred, model_name: str):\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    roc_auc = roc_auc_score(y_true, y_pred)\n",
        "\n",
        "    print(f\"\\n{model_name} Results:\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1-Score: {f1:.4f}\")\n",
        "    print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_true, y_pred))\n",
        "\n",
        "    return recall\n"
      ],
      "metadata": {
        "id": "GhAx4W6zfJwe"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: FastAPI Deployment\n",
        "app = FastAPI(title=\"Fraud Detection API\")\n",
        "\n",
        "class Transaction(BaseModel):\n",
        "    features: List[float]\n",
        "\n",
        "@app.post(\"/predict\")\n",
        "async def predict_fraud(transaction: Transaction):\n",
        "    # Load models and scaler\n",
        "    lr_model = pickle.load(open('lr_model.pkl', 'rb'))\n",
        "    rf_model = pickle.load(open('rf_model.pkl', 'rb'))\n",
        "    autoencoder = tf.keras.models.load_model('autoencoder.h5')\n",
        "    scaler = pickle.load(open('scaler.pkl', 'rb'))\n",
        "\n",
        "    # Prepare input\n",
        "    X = np.array([transaction.features])\n",
        "    X_scaled = scaler.transform(X)\n",
        "\n",
        "    # Predict\n",
        "    lr_pred = lr_model.predict(X_scaled)[0]\n",
        "    rf_pred = rf_model.predict(X_scaled)[0]\n",
        "    reconstructions = autoencoder.predict(X_scaled, verbose=0)\n",
        "    mse = np.mean(np.power(X_scaled - reconstructions, 2), axis=1)\n",
        "    auto_pred = int(mse[0] > 2.0)\n",
        "\n",
        "    return {\n",
        "        \"LogisticRegression\": \"Fraud\" if lr_pred else \"Legit\",\n",
        "        \"RandomForest\": \"Fraud\" if rf_pred else \"Legit\",\n",
        "        \"Autoencoder\": \"Fraud\" if auto_pred else \"Legit\"\n",
        "    }"
      ],
      "metadata": {
        "id": "8ENBXHkYfMn1"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main Execution\n",
        "def run_fraud_detection():\n",
        "    print(\"=== Fraud Detection in Financial Transactions ===\\n\")\n",
        "\n",
        "    # Generate and preprocess data\n",
        "    df = generate_synthetic_data(n_samples=10000)\n",
        "    X_train, X_test, y_train, y_test, scaler = preprocess_data(df)\n",
        "    pickle.dump(scaler, open('scaler.pkl', 'wb'))\n",
        "\n",
        "    # Initialize and train models\n",
        "    models = FraudModels()\n",
        "    print(\"Training Logistic Regression...\")\n",
        "    models.train_logistic_regression(X_train, y_train)\n",
        "    print(\"Training Random Forest...\")\n",
        "    models.train_random_forest(X_train, y_train)\n",
        "    print(\"Training Autoencoder...\")\n",
        "    models.train_autoencoder(X_train, y_train)\n",
        "\n",
        "    # Evaluate models\n",
        "    lr_pred = models.predict_lr(X_test)\n",
        "    rf_pred = models.predict_rf(X_test)\n",
        "    auto_pred = models.predict_autoencoder(X_test)\n",
        "\n",
        "    lr_recall = evaluate_model(y_test, lr_pred, \"Logistic Regression\")\n",
        "    rf_recall = evaluate_model(y_test, rf_pred, \"Random Forest\")\n",
        "    auto_recall = evaluate_model(y_test, auto_pred, \"Autoencoder\")\n",
        "\n",
        "    # Compare to baseline (no SMOTE, simple LR)\n",
        "    baseline_lr = LogisticRegression(random_state=42)\n",
        "    X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(\n",
        "        df.drop('Class', axis=1), df['Class'], test_size=0.2, stratify=df['Class'], random_state=42\n",
        "    )\n",
        "    scaler_baseline = StandardScaler()\n",
        "    X_train_raw_scaled = scaler_baseline.fit_transform(X_train_raw)\n",
        "    baseline_lr.fit(X_train_raw_scaled, y_train_raw)\n",
        "    baseline_pred = baseline_lr.predict(scaler_baseline.transform(X_test_raw))\n",
        "    baseline_recall = evaluate_model(y_test_raw, baseline_pred, \"Baseline Logistic Regression\")\n",
        "\n",
        "    # Quantify false negative reduction\n",
        "    fn_reduction = ((baseline_recall - max(lr_recall, rf_recall, auto_recall)) / baseline_recall) * 100\n",
        "    print(f\"\\nFalse Negative Reduction: ~{abs(fn_reduction):.0f}% (target: 30%)\")\n",
        "\n",
        "    print(\"\\nTo test API, run: uvicorn fraud_detection:app --reload\")\n",
        "    print(\"Then visit http://127.0.0.1:8000/docs to test predictions.\")\n",
        "if __name__ == \"__main__\":\n",
        "   run_fraud_detection()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijFTHGoAfTQ8",
        "outputId": "10635c38-a3b0-4791-fdc1-b6dbd0541e15"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Fraud Detection in Financial Transactions ===\n",
            "\n",
            "Training Logistic Regression...\n",
            "Training Random Forest...\n",
            "Training Autoencoder...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Logistic Regression Results:\n",
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "ROC-AUC: 1.0000\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1997\n",
            "           1       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           1.00      2000\n",
            "   macro avg       1.00      1.00      1.00      2000\n",
            "weighted avg       1.00      1.00      1.00      2000\n",
            "\n",
            "\n",
            "Random Forest Results:\n",
            "Precision: 0.0000\n",
            "Recall: 0.0000\n",
            "F1-Score: 0.0000\n",
            "ROC-AUC: 0.5000\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1997\n",
            "           1       0.00      0.00      0.00         3\n",
            "\n",
            "    accuracy                           1.00      2000\n",
            "   macro avg       0.50      0.50      0.50      2000\n",
            "weighted avg       1.00      1.00      1.00      2000\n",
            "\n",
            "\n",
            "Autoencoder Results:\n",
            "Precision: 0.0000\n",
            "Recall: 0.0000\n",
            "F1-Score: 0.0000\n",
            "ROC-AUC: 0.5000\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1997\n",
            "           1       0.00      0.00      0.00         3\n",
            "\n",
            "    accuracy                           1.00      2000\n",
            "   macro avg       0.50      0.50      0.50      2000\n",
            "weighted avg       1.00      1.00      1.00      2000\n",
            "\n",
            "\n",
            "Baseline Logistic Regression Results:\n",
            "Precision: 1.0000\n",
            "Recall: 0.6667\n",
            "F1-Score: 0.8000\n",
            "ROC-AUC: 0.8333\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1997\n",
            "           1       1.00      0.67      0.80         3\n",
            "\n",
            "    accuracy                           1.00      2000\n",
            "   macro avg       1.00      0.83      0.90      2000\n",
            "weighted avg       1.00      1.00      1.00      2000\n",
            "\n",
            "\n",
            "False Negative Reduction: ~50% (target: 30%)\n",
            "\n",
            "To test API, run: uvicorn fraud_detection:app --reload\n",
            "Then visit http://127.0.0.1:8000/docs to test predictions.\n"
          ]
        }
      ]
    }
  ]
}